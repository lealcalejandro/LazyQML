{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#_1","title":"Home","text":"<p>LazyQML is a Python library designed to streamline, automate, and accelerate experimentation with Quantum Machine Learning (QML) architectures, right on classical computers.</p> <p>With LazyQML, you can:   - \ud83d\udee0\ufe0f Build, test, and benchmark QML models with minimal effort.</p> <ul> <li> <p>\u26a1 Compare different QML architectures, hyperparameters seamlessly.</p> </li> <li> <p>\ud83e\udde0 Gather knowledge about the most suitable architecture for your problem.</p> </li> </ul>"},{"location":"#why-lazyqml","title":"\u2728 Why LazyQML?","text":"<ul> <li> <p>Rapid Prototyping: Experiment with different QML models using just a few lines of code.</p> </li> <li> <p>Automated Benchmarking: Evaluate performance and trade-offs across architectures effortlessly.</p> </li> <li> <p>Flexible &amp; Modular: From basic quantum circuits to hybrid quantum-classical models\u2014LazyQML has you covered.</p> </li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<p>For detailed usage instructions, API reference, and code examples, please refer to the official LazyQML documentation.</p>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python &gt;= 3.10</li> </ul> <p>\u2757\u2757  This library is only supported by Linux Systems. It doesn't support Windows nor MacOS.  Only supports CUDA compatible devices.</p>"},{"location":"#installation","title":"Installation","text":"<p>To install lazyqml, run this command in your terminal:</p> <pre><code>pip install lazyqml\n</code></pre> <p>This is the preferred method to install lazyqml, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"#from-sources","title":"From sources","text":"<p>To install lazyqml from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/QHPC-SP-Research-Lab/LazyQML\n</code></pre>"},{"location":"#example","title":"Example","text":"<pre><code>from sklearn.datasets import load_iris\nfrom lazyqml.lazyqml import *\n\n# Load data\ndata = load_iris()\nX = data.data\ny = data.target\n\nclassifier = QuantumClassifier(nqubits={4}, classifiers={Model.QNN, Model.QSVM}, epochs=10)\n\n# Fit and predict\nclassifier.fit(X=X, y=y, test_size=0.4)\n</code></pre>"},{"location":"#quantum-and-high-performance-computing-qhpc-university-of-oviedo","title":"Quantum and High Performance Computing (QHPC) - University of Oviedo","text":"<ul> <li>Jos\u00e9 Ranilla Pastor - ranilla@uniovi.es</li> <li>El\u00edas Fern\u00e1ndez Combarro - efernandezca@uniovi.es</li> <li>Diego Garc\u00eda Vega - diegogarciavega@gmail.com</li> <li>Fernando \u00c1lvaro Plou Llorente - ploufernando@uniovi.es</li> <li>Alejandro Leal Casta\u00f1o - lealcalejandro@uniovi.es</li> <li>Group - https://qhpc.uniovi.es</li> </ul>"},{"location":"#citing","title":"Citing","text":"<p>If you used LazyQML in your work, please cite: - Garc\u00eda-Vega, D., Plou Llorente, F., Leal Casta\u00f1o, A., Combarro, E.F., Ranilla, J.: Lazyqml: A python library to benchmark quantum machine learning models. In: 30th European Conference on Parallel and Distributed Processing (2024)</p>"},{"location":"#license","title":"License","text":"<ul> <li>Free software: MIT License</li> </ul>"},{"location":"api/","title":"Introduction","text":"<p>Certainly! Here's the complete markdown code with a bit of flair to make the documentation more engaging, all ready for you to copy and use:</p>"},{"location":"api/#lazyqml-api-overview","title":"LazyQML API Overview","text":"<p>Welcome to LazyQML \u2013 your quantum machine learning playground! LazyQML is a cutting-edge Python library designed to simplify the integration of quantum classifiers into your machine learning workflows. With LazyQML, you'll be able to explore quantum neural networks, quantum support vector machines, and other quantum models, all while maintaining a simple and easy to use code.</p> <p>At the heart of LazyQML is the QuantumClassifier \u2013 the Swiss Army knife of quantum machine learning. This easy-to-use class empowers you to train, evaluate, and fine-tune quantum classifiers on your data, whether you're a beginner or a seasoned quantum enthusiast. </p>"},{"location":"api/#key-features","title":"Key Features","text":"<p>LazyQML is packed with tools to streamline quantum classification. Below are the core features that set it apart from the crowd:</p>"},{"location":"api/#1-quantumclassifier-the-heart-of-lazyqml","title":"1. QuantumClassifier: The Heart of LazyQML","text":"<p>The QuantumClassifier class is the core of LazyQML, offering a variety of methods for training and evaluating quantum models. It provides an elegant and flexible interface for working with quantum circuits, allowing you to explore different types of classifiers, embeddings, and ansatz circuits. The goal? To make quantum classification as intuitive as possible. </p>"},{"location":"api/#2-variants-of-quantumclassifier","title":"2. Variants of QuantumClassifier","text":"<p>LazyQML provides two exciting variants of the QuantumClassifier, depending on which module you import. This gives you the freedom to choose the right quantum simulation backend for your specific needs:</p> <ul> <li> <p>State Vector Simulation (imported from <code>lazyqml.st</code>): This variant simulates the full quantum state of your system, perfect for smaller systems or when you want a more intuitive understanding of quantum behavior.</p> </li> <li> <p>Tensor Networks (imported from <code>lazyqml.tn</code>): This variant uses tensor networks, providing higher scalability for larger quantum systems. It's optimized for more complex and larger datasets, helping you tackle big problems with ease.</p> </li> </ul>"},{"location":"api/#importing-state-vector-simulation-variant","title":"Importing State Vector Simulation Variant:","text":"<pre><code>from lazyqml.st import *\n</code></pre> <ul> <li>Use this import to access the QuantumClassifier based on State Vector simulations, simulating the full quantum state for an intuitive understanding.</li> </ul>"},{"location":"api/#importing-tensor-network-variant","title":"Importing Tensor Network Variant:","text":"<p><pre><code>from lazyqml.tn import *\n</code></pre> - Use this import to access the QuantumClassifier based on Tensor Networks, offering efficient simulation of larger quantum systems using approximate methods.</p>"},{"location":"api/#3-training-and-evaluation-methods","title":"3. Training and Evaluation Methods","text":"<p>LazyQML offers you three robust methods to train and evaluate your quantum models. These methods are designed to give you complete control over the classification process:</p>"},{"location":"api/#fit","title":"fit","text":"<p>The fit method is where the magic happens. \ud83c\udf1f It trains your quantum model on your dataset, selecting from different quantum classifiers, embeddings, and ansatz circuits. This method provides a simple interface to quickly train a model, view its results, and get on with your quantum journey.</p> <ul> <li>When to use it? Use fit when you want to quickly train and evaluate a quantum model with just a few lines of code.</li> </ul>"},{"location":"api/#leave_one_out","title":"leave_one_out","text":"<p>Leave-One-Out Cross Validation (LOO CV) is a robust technique where each data point is used as the test set exactly once. This method is fantastic for small datasets, providing a deeper understanding of your model\u2019s performance.</p> <ul> <li>When to use it? Choose leave_one_out when working with small datasets and you need to evaluate every data point for a thorough assessment.</li> </ul>"},{"location":"api/#repeated_cross_validation","title":"repeated_cross_validation","text":"<p>This method performs repeated k-fold cross-validation. It divides your dataset into k subsets, trains the model on k-1 subsets, and tests on the remaining fold. This process is repeated multiple times to provide a more accurate estimate of your model's performance.</p> <ul> <li>When to use it? Use repeated_cross_validation for a more comprehensive evaluation of your model, especially when working with larger datasets.</li> </ul>"},{"location":"api/#4-enums-for-quantum-model-selection","title":"4. Enums for Quantum Model Selection","text":"<p>LazyQML gives you full control over your quantum model's architecture. With a rich set of enums, you can easily select the correct ansatz circuits, embedding strategies, and classification models. \ud83c\udfaf</p>"},{"location":"api/#ansatzs-enum","title":"Ansatzs Enum","text":"<p>Ansatz circuits define the structure of your quantum model. LazyQML provides a selection of ansatz types:</p> <ul> <li><code>ALL</code>: All available ansatz circuits.</li> <li><code>HCZRX</code>, <code>TREE_TENSOR</code>, <code>TWO_LOCAL</code>, <code>HARDWARE_EFFICIENT</code>: Popular ansatz circuits that are ideal for quantum machine learning.</li> </ul>"},{"location":"api/#embedding-enum","title":"Embedding Enum","text":"<p>Embeddings control how your classical data is encoded onto quantum states. LazyQML offers several types of embedding strategies:</p> <ul> <li><code>ALL</code>: All available embedding circuits.</li> <li><code>RX</code>, <code>RY</code>, <code>RZ</code>: Common qubit rotation embeddings.</li> <li><code>ZZ</code>, <code>AMP</code>: Embedding strategies based on entanglement or amplitude encoding.</li> </ul>"},{"location":"api/#model-enum","title":"Model Enum","text":"<p>LazyQML supports a variety of quantum models, each suited for different tasks. Choose the model that best fits your data and problem:</p> <ul> <li><code>ALL</code>: All available quantum models.</li> <li><code>QNN</code>: Quantum Neural Network.</li> <li><code>QNN_BAG</code>: Quantum Neural Network with Bagging.</li> <li><code>QSVM</code>: Quantum Support Vector Machine.</li> <li><code>QKNN</code>: Quantum k-Nearest Neighbors.</li> </ul>"},{"location":"api/#whats-next","title":"What's Next?","text":"<p>This overview introduces you to the powerful features of LazyQML and the QuantumClassifier. Whether you\u2019re just getting started or you\u2019re a quantum computing pro, LazyQML simplifies quantum machine learning. \ud83c\udf10\u2728</p> <p>For more detailed documentation on each function, parameter, and quantum algorithm, head over to the full documentation pages. Get ready to dive into the world of quantum classification with LazyQML \u2013 your quantum adventure begins here! \ud83d\udef8</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"common/","title":"common module","text":""},{"location":"common/#lazyqml.lazyqml.QuantumClassifier","title":"<code> QuantumClassifier            (BaseModel)         </code>","text":"<p>This module helps in fitting to all the classification algorithms that are available in Scikit-learn Parameters</p> <p>verbose : bool, optional (default=False)     Verbose True for showing every training message during the fit. ignoreWarnings : bool, optional (default=True)     When set to True, the warning related to algorigms that are not able to run are ignored. customMetric : function, optional (default=None)     When function is provided, models are evaluated based on the custom evaluation metric provided. customImputerNum : function, optional (default=None)     When function is provided, models are imputed based on the custom numeric imputer provided. customImputerCat : function, optional (default=None)     When function is provided, models are imputed based on the custom categorical imputer provided. prediction : bool, optional (default=False)     When set to True, the predictions of all the models models are returned as a pandas dataframe. classifiers : list of strings, optional (default=[\"all\"])     When function is provided, trains the chosen classifier(s) [\"all\", \"qsvm\", \"qnn\", \"qnnbag\"]. embeddings : list of strings, optional (default=[\"all\"])     When function is provided, trains the chosen embeddings(s) [\"all\", \"amplitude_embedding\", \"ZZ_embedding\", \"rx_embedding\", \"rz_embedding\", \"ry_embedding\"]. ansatzs : list of strings, optional (default=[\"all\"])     When function is provided, trains the chosen ansatzs(s) [\"all\", \"HPzRx\", \"tree_tensor\", \"two_local\", \"hardware_efficient\"]. randomSate : int, optional (default=1234)     This integer is used as a seed for the repeatability of the experiments. nqubits : int, optional (default=8)     This integer is used for defining the number of qubits of the quantum circuits that the models will use. numLayers : int, optional (default=5)     The number of layers that the Quantum Neural Network (QNN) models will use, is set to 5 by default. numPredictors : int, optional (default=10)     The number of different predictoras that the Quantum Neural Networks with Bagging (QNN_Bag) will use, is set to 10 by default. learningRate : int, optional (default=0.01)     The parameter that will be used for the optimization process of all the Quantum Neural Networks (QNN) in the gradient descent, is set to 0.01 by default. epochs : int, optional (default=100)     The number of complete passes that will be done over the dataset during the fitting of the models. runs : int, optional (default=1)     The number of training runs that will be done with the Quantum Neural Network (QNN) models. maxSamples : float, optiona (default=1.0)     A floating point number between 0 and 1.0 that indicates the percentage of the dataset that will be used for each Quantum Neural Network with Bagging (QNN_Bag).</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier--examples","title":"Examples","text":"<p>from lazyqml.supervised import QuantumClassifier from sklearn.datasets import load_breast_cancer from sklearn.model_selection import train_test_split data = load_breast_cancer() X = data.data y= data.target X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.5,random_state =123) clf = QuantumClassifier(verbose=0,ignore_warnings=True, customMetric=None) models,predictions = clf.fit(X_train, X_test, y_train, y_test) model_dictionary = clf.provide_models(X_train,X_test,y_train,y_test) models | Model       | Embedding           | Ansatz             |   Accuracy |   Balanced Accuracy |   ROC AUC |   F1 Score |   Time taken | |:------------|:--------------------|:-------------------|-----------:|--------------------:|----------:|-----------:|-------------:| | qsvm        | amplitude_embedding | ~                  |   0.807018 |            0.782339 |  0.782339 |   0.802547 |     43.7487  | | qnn         | amplitude_embedding | hardware_efficient |   0.77193  |            0.743218 |  0.743218 |   0.765533 |      7.92101 | | qnn         | ry_embedding        | hardware_efficient |   0.71345  |            0.689677 |  0.689677 |   0.709295 |      8.00107 | .....................................................................................................................................</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier--_1","title":"common module","text":"<p>..................................................................................................................................... | qnn         | ZZ_embedding        | two_local          |   0.461988 |            0.455954 |  0.455954 |   0.467481 |      2.13294 |</p> Source code in <code>lazyqml/lazyqml.py</code> <pre><code>class QuantumClassifier(BaseModel):\n    \"\"\"\n    This module helps in fitting to all the classification algorithms that are available in Scikit-learn\n    Parameters\n    ----------\n    verbose : bool, optional (default=False)\n        Verbose True for showing every training message during the fit.\n    ignoreWarnings : bool, optional (default=True)\n        When set to True, the warning related to algorigms that are not able to run are ignored.\n    customMetric : function, optional (default=None)\n        When function is provided, models are evaluated based on the custom evaluation metric provided.\n    customImputerNum : function, optional (default=None)\n        When function is provided, models are imputed based on the custom numeric imputer provided.\n    customImputerCat : function, optional (default=None)\n        When function is provided, models are imputed based on the custom categorical imputer provided.\n    prediction : bool, optional (default=False)\n        When set to True, the predictions of all the models models are returned as a pandas dataframe.\n    classifiers : list of strings, optional (default=[\"all\"])\n        When function is provided, trains the chosen classifier(s) [\"all\", \"qsvm\", \"qnn\", \"qnnbag\"].\n    embeddings : list of strings, optional (default=[\"all\"])\n        When function is provided, trains the chosen embeddings(s) [\"all\", \"amplitude_embedding\", \"ZZ_embedding\", \"rx_embedding\", \"rz_embedding\", \"ry_embedding\"].\n    ansatzs : list of strings, optional (default=[\"all\"])\n        When function is provided, trains the chosen ansatzs(s) [\"all\", \"HPzRx\", \"tree_tensor\", \"two_local\", \"hardware_efficient\"].\n    randomSate : int, optional (default=1234)\n        This integer is used as a seed for the repeatability of the experiments.\n    nqubits : int, optional (default=8)\n        This integer is used for defining the number of qubits of the quantum circuits that the models will use.\n    numLayers : int, optional (default=5)\n        The number of layers that the Quantum Neural Network (QNN) models will use, is set to 5 by default.\n    numPredictors : int, optional (default=10)\n        The number of different predictoras that the Quantum Neural Networks with Bagging (QNN_Bag) will use, is set to 10 by default.\n    learningRate : int, optional (default=0.01)\n        The parameter that will be used for the optimization process of all the Quantum Neural Networks (QNN) in the gradient descent, is set to 0.01 by default.\n    epochs : int, optional (default=100)\n        The number of complete passes that will be done over the dataset during the fitting of the models.\n    runs : int, optional (default=1)\n        The number of training runs that will be done with the Quantum Neural Network (QNN) models.\n    maxSamples : float, optiona (default=1.0)\n        A floating point number between 0 and 1.0 that indicates the percentage of the dataset that will be used for each Quantum Neural Network with Bagging (QNN_Bag).\n\n    Examples\n    --------\n    &gt;&gt;&gt; from lazyqml.supervised import QuantumClassifier\n    &gt;&gt;&gt; from sklearn.datasets import load_breast_cancer\n    &gt;&gt;&gt; from sklearn.model_selection import train_test_split\n    &gt;&gt;&gt; data = load_breast_cancer()\n    &gt;&gt;&gt; X = data.data\n    &gt;&gt;&gt; y= data.target\n    &gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.5,random_state =123)\n    &gt;&gt;&gt; clf = QuantumClassifier(verbose=0,ignore_warnings=True, customMetric=None)\n    &gt;&gt;&gt; models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n    &gt;&gt;&gt; model_dictionary = clf.provide_models(X_train,X_test,y_train,y_test)\n    &gt;&gt;&gt; models\n    | Model       | Embedding           | Ansatz             |   Accuracy |   Balanced Accuracy |   ROC AUC |   F1 Score |   Time taken |\n    |:------------|:--------------------|:-------------------|-----------:|--------------------:|----------:|-----------:|-------------:|\n    | qsvm        | amplitude_embedding | ~                  |   0.807018 |            0.782339 |  0.782339 |   0.802547 |     43.7487  |\n    | qnn         | amplitude_embedding | hardware_efficient |   0.77193  |            0.743218 |  0.743218 |   0.765533 |      7.92101 |\n    | qnn         | ry_embedding        | hardware_efficient |   0.71345  |            0.689677 |  0.689677 |   0.709295 |      8.00107 |\n    .....................................................................................................................................\n    #####################################################################################################################################\n    .....................................................................................................................................\n    | qnn         | ZZ_embedding        | two_local          |   0.461988 |            0.455954 |  0.455954 |   0.467481 |      2.13294 |\n    \"\"\"\n    model_config = ConfigDict(strict=True)\n\n    # nqubits: Annotated[int, Field(gt=0)] = 8\n    nqubits: Annotated[Set[int], Field(description=\"Set of qubits, each must be greater than 0\")]\n    randomstate: int = 1234\n    predictions: bool = False\n    ignoreWarnings: bool = True\n    sequential: bool = False\n    numPredictors: Annotated[int, Field(gt=0)] = 10\n    numLayers: Annotated[int, Field(gt=0)] = 5\n    classifiers: Annotated[Set[Model], Field(min_items=1)] = {Model.ALL}\n    ansatzs: Annotated[Set[Ansatzs], Field(min_items=1)] = {Ansatzs.ALL}\n    embeddings: Annotated[Set[Embedding], Field(min_items=1)] = {Embedding.ALL}\n    backend: Backend = Backend.lightningQubit\n    features: Annotated[Set[float], Field(min_items=1)] = {0.3, 0.5, 0.8}\n    learningRate: Annotated[float, Field(gt=0)] = 0.01\n    epochs: Annotated[int, Field(gt=0)] = 100\n    shots: Annotated[int, Field(gt=0)] = 1\n    runs: Annotated[int, Field(gt=0)] = 1\n    batchSize: Annotated[int, Field(gt=0)] = 8\n    threshold: Annotated[int, Field(gt=0)] = 22\n    maxSamples: Annotated[float, Field(gt=0, le=1)] = 1.0\n    verbose: bool = False\n    customMetric: Optional[Callable] = None\n    customImputerNum: Optional[Any] = None\n    customImputerCat: Optional[Any] = None\n    cores: Optional[int] = True\n\n    @field_validator('nqubits', mode='before')\n    def check_nqubits_positive(cls, value):\n        if not isinstance(value, set):\n            raise TypeError('nqubits must be a set of integers')\n\n        if any(v &lt;= 0 for v in value):\n            raise ValueError('Each value in nqubits must be greater than 0')\n\n        return value\n\n    @field_validator('features')\n    def validate_features(cls, v):\n        if not all(0 &lt; x &lt;= 1 for x in v):\n            raise ValueError(\"All features must be greater than 0 and less than or equal to 1\")\n        return v\n\n    @field_validator('customMetric')\n    def validate_custom_metric_field(cls, metric):\n        if metric is None:\n            return None  # Allow None as a valid value\n\n        # Check the function signature\n        sig = inspect.signature(metric)\n        params = list(sig.parameters.values())\n\n        if len(params) &lt; 2 or params[0].name != 'y_true' or params[1].name != 'y_pred':\n            raise ValueError(\n                f\"Function {metric.__name__} does not have the required signature. \"\n                f\"Expected first two arguments to be 'y_true' and 'y_pred'.\"\n            )\n\n        # Test the function by passing dummy arguments\n        y_true = np.array([0, 1, 1, 0])  # Example ground truth labels\n        y_pred = np.array([0, 1, 0, 0])  # Example predicted labels\n\n        try:\n            result = metric(y_true, y_pred)\n        except Exception as e:\n            raise ValueError(f\"Function {metric.__name__} raised an error during execution: {e}\")\n\n        # Ensure the result is a scalar (int or float)\n        if not isinstance(result, (int, float)):\n            raise ValueError(\n                f\"Function {metric.__name__} returned {result}, which is not a scalar value.\"\n            )\n\n        return metric\n\n    @field_validator('customImputerCat', 'customImputerNum')\n    def check_preprocessor_methods(cls, preprocessor):\n        # Check if preprocessor is an instance of a class\n        if not isinstance(preprocessor, object):\n            raise ValueError(\n                f\"Expected an instance of a class, but got {type(preprocessor).__name__}.\"\n            )\n\n        # Ensure the object has 'fit' and 'transform' methods\n        if not (hasattr(preprocessor, 'fit') and hasattr(preprocessor, 'transform')):\n            raise ValueError(\n                f\"Object {preprocessor.__class__.__name__} does not have required methods 'fit' and 'transform'.\"\n            )\n\n        # Optionally check if the object has 'fit_transform' method\n        if not hasattr(preprocessor, 'fit_transform'):\n            raise ValueError(\n                f\"Object {preprocessor.__class__.__name__} does not have 'fit_transform' method.\"\n            )\n\n        # Create dummy data for testing the preprocessor methods\n        X_dummy = np.array([[1, 2], [3, 4], [5, 6]])  # Example dummy data\n\n        try:\n            # Ensure the object can fit on data\n            preprocessor.fit(X_dummy)\n        except Exception as e:\n            raise ValueError(f\"Object {preprocessor.__class__.__name__} failed to fit: {e}\")\n\n        try:\n            # Ensure the object can transform data\n            transformed = preprocessor.transform(X_dummy)\n        except Exception as e:\n            raise ValueError(f\"Object {preprocessor.__class__.__name__} failed to transform: {e}\")\n\n        # Check the type of the transformed result\n        if not isinstance(transformed, (np.ndarray, list)):\n            raise ValueError(\n                f\"Object {preprocessor.__class__.__name__} returned {type(transformed)} from 'transform', expected np.ndarray or list.\"\n            )\n\n        return preprocessor\n\n    def fit(self, X, y, test_size=0.4, showTable=True):\n        \"\"\"\n\n        \"\"\"\n        warnings.filterwarnings(\"ignore\")\n        printer.set_verbose(verbose=self.verbose)\n        # Validation model to ensure input parameters are DataFrames and sizes match\n        FitParamsValidatorCV(\n            x=X,\n            y=y\n        )\n        printer.print(\"Validation successful, fitting the model...\")\n\n        # Fix seed\n        fixSeed(self.randomstate)\n        d = Dispatcher(sequential=self.sequential,threshold=self.threshold,repeats=1, folds=1)\n        d.dispatch(nqubits=self.nqubits,randomstate=self.randomstate,predictions=self.predictions,numPredictors=self.numPredictors,numLayers=self.numLayers,classifiers=self.classifiers,ansatzs=self.ansatzs,backend=self.backend,embeddings=self.embeddings,features=self.features,learningRate=self.learningRate,epochs=self.epochs,runs=self.runs,maxSamples=self.maxSamples,verbose=self.verbose,customMetric=self.customMetric,customImputerNum=self.customImputerNum,customImputerCat=self.customImputerCat, X=X ,y=y,shots=self.shots,showTable=showTable,batch=self.batchSize,mode=\"holdout\",testsize=test_size)\n\n    def repeated_cross_validation(self, X, y, n_splits=10, n_repeats=5, showTable=True):\n        \"\"\"\n\n        \"\"\"\n        warnings.filterwarnings(\"ignore\")\n        printer.set_verbose(verbose=self.verbose)\n        # Validation model to ensure input parameters are DataFrames and sizes match\n        FitParamsValidatorCV(\n            x=X,\n            y=y\n        )\n        printer.print(\"Validation successful, fitting the model...\")\n\n        # Fix seed\n        fixSeed(self.randomstate)\n        d = Dispatcher(sequential=self.sequential,threshold=self.threshold,repeats=n_repeats,folds=n_splits)\n        d.dispatch(nqubits=self.nqubits,randomstate=self.randomstate,predictions=self.predictions,numPredictors=self.numPredictors,numLayers=self.numLayers,classifiers=self.classifiers,ansatzs=self.ansatzs,backend=self.backend,embeddings=self.embeddings,features=self.features,learningRate=self.learningRate,epochs=self.epochs,runs=self.runs,maxSamples=self.maxSamples,verbose=self.verbose,customMetric=self.customMetric,customImputerNum=self.customImputerNum,customImputerCat=self.customImputerCat,X=X ,y=y,shots=self.shots,showTable=showTable,batch=self.batchSize,mode=\"cross-validation\")\n\n    def leave_one_out(self, X, y, showTable=True):\n        \"\"\"\n\n        \"\"\"\n        warnings.filterwarnings(\"ignore\")\n        printer.set_verbose(verbose=self.verbose)\n        # Validation model to ensure input parameters are DataFrames and sizes match\n        FitParamsValidatorCV(\n            x=X,\n            y=y\n        )\n        printer.print(\"Validation successful, fitting the model...\")\n\n        # Fix seed \n        fixSeed(self.randomstate)\n        d = Dispatcher(sequential=self.sequential,threshold=self.threshold,folds=len(X),repeats=1)\n        d.dispatch(nqubits=self.nqubits,randomstate=self.randomstate,predictions=self.predictions,numPredictors=self.numPredictors,numLayers=self.numLayers,classifiers=self.classifiers,ansatzs=self.ansatzs,backend=self.backend,embeddings=self.embeddings,features=self.features,learningRate=self.learningRate,epochs=self.epochs,runs=self.runs,maxSamples=self.maxSamples,verbose=self.verbose,customMetric=self.customMetric,customImputerNum=self.customImputerNum,customImputerCat=self.customImputerCat,X=X ,y=y,shots=self.shots,showTable=showTable,batch=self.batchSize,mode=\"leave-one-out\")\n</code></pre>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.__class_vars__","title":"<code>__class_vars__</code>  <code>special</code>","text":"<p>The names of the class variables defined on the model.</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.__private_attributes__","title":"<code>__private_attributes__</code>  <code>special</code>","text":"<p>Metadata about the private attributes of the model.</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.__pydantic_complete__","title":"<code>__pydantic_complete__</code>  <code>special</code>","text":"<p>Whether model building is completed, or if there are still undefined fields.</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.__pydantic_computed_fields__","title":"<code>__pydantic_computed_fields__</code>  <code>special</code>","text":"<p>A dictionary of computed field names and their corresponding <code>ComputedFieldInfo</code> objects.</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.__pydantic_custom_init__","title":"<code>__pydantic_custom_init__</code>  <code>special</code>","text":"<p>Whether the model has a custom <code>__init__</code> method.</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.__pydantic_decorators__","title":"<code>__pydantic_decorators__</code>  <code>special</code>","text":"<p>Metadata containing the decorators defined on the model. This replaces <code>Model.__validators__</code> and <code>Model.__root_validators__</code> from Pydantic V1.</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.__pydantic_fields__","title":"<code>__pydantic_fields__</code>  <code>special</code>","text":"<p>A dictionary of field names and their corresponding <code>FieldInfo</code> objects. This replaces <code>Model.__fields__</code> from Pydantic V1.</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.__pydantic_generic_metadata__","title":"<code>__pydantic_generic_metadata__</code>  <code>special</code>","text":"<p>Metadata for generic models; contains data used for a similar purpose to args, origin, parameters in typing-module generics. May eventually be replaced by these.</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.__pydantic_parent_namespace__","title":"<code>__pydantic_parent_namespace__</code>  <code>special</code>","text":"<p>Parent namespace of the model, used for automatic rebuilding of models.</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.__pydantic_post_init__","title":"<code>__pydantic_post_init__</code>  <code>special</code>","text":"<p>The name of the post-init method for the model, if defined.</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.__signature__","title":"<code>__signature__</code>  <code>special</code>","text":"<p>The synthesized <code>__init__</code> <code>Signature</code> of the model.</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.model_config","title":"<code>model_config</code>","text":"<p>Configuration for the model, should be a dictionary conforming to <code>ConfigDict</code>.</p>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.fit","title":"<code>fit(self, X, y, test_size=0.4, showTable=True)</code>","text":"Source code in <code>lazyqml/lazyqml.py</code> <pre><code>def fit(self, X, y, test_size=0.4, showTable=True):\n    \"\"\"\n\n    \"\"\"\n    warnings.filterwarnings(\"ignore\")\n    printer.set_verbose(verbose=self.verbose)\n    # Validation model to ensure input parameters are DataFrames and sizes match\n    FitParamsValidatorCV(\n        x=X,\n        y=y\n    )\n    printer.print(\"Validation successful, fitting the model...\")\n\n    # Fix seed\n    fixSeed(self.randomstate)\n    d = Dispatcher(sequential=self.sequential,threshold=self.threshold,repeats=1, folds=1)\n    d.dispatch(nqubits=self.nqubits,randomstate=self.randomstate,predictions=self.predictions,numPredictors=self.numPredictors,numLayers=self.numLayers,classifiers=self.classifiers,ansatzs=self.ansatzs,backend=self.backend,embeddings=self.embeddings,features=self.features,learningRate=self.learningRate,epochs=self.epochs,runs=self.runs,maxSamples=self.maxSamples,verbose=self.verbose,customMetric=self.customMetric,customImputerNum=self.customImputerNum,customImputerCat=self.customImputerCat, X=X ,y=y,shots=self.shots,showTable=showTable,batch=self.batchSize,mode=\"holdout\",testsize=test_size)\n</code></pre>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.leave_one_out","title":"<code>leave_one_out(self, X, y, showTable=True)</code>","text":"Source code in <code>lazyqml/lazyqml.py</code> <pre><code>def leave_one_out(self, X, y, showTable=True):\n    \"\"\"\n\n    \"\"\"\n    warnings.filterwarnings(\"ignore\")\n    printer.set_verbose(verbose=self.verbose)\n    # Validation model to ensure input parameters are DataFrames and sizes match\n    FitParamsValidatorCV(\n        x=X,\n        y=y\n    )\n    printer.print(\"Validation successful, fitting the model...\")\n\n    # Fix seed \n    fixSeed(self.randomstate)\n    d = Dispatcher(sequential=self.sequential,threshold=self.threshold,folds=len(X),repeats=1)\n    d.dispatch(nqubits=self.nqubits,randomstate=self.randomstate,predictions=self.predictions,numPredictors=self.numPredictors,numLayers=self.numLayers,classifiers=self.classifiers,ansatzs=self.ansatzs,backend=self.backend,embeddings=self.embeddings,features=self.features,learningRate=self.learningRate,epochs=self.epochs,runs=self.runs,maxSamples=self.maxSamples,verbose=self.verbose,customMetric=self.customMetric,customImputerNum=self.customImputerNum,customImputerCat=self.customImputerCat,X=X ,y=y,shots=self.shots,showTable=showTable,batch=self.batchSize,mode=\"leave-one-out\")\n</code></pre>"},{"location":"common/#lazyqml.lazyqml.QuantumClassifier.repeated_cross_validation","title":"<code>repeated_cross_validation(self, X, y, n_splits=10, n_repeats=5, showTable=True)</code>","text":"Source code in <code>lazyqml/lazyqml.py</code> <pre><code>def repeated_cross_validation(self, X, y, n_splits=10, n_repeats=5, showTable=True):\n    \"\"\"\n\n    \"\"\"\n    warnings.filterwarnings(\"ignore\")\n    printer.set_verbose(verbose=self.verbose)\n    # Validation model to ensure input parameters are DataFrames and sizes match\n    FitParamsValidatorCV(\n        x=X,\n        y=y\n    )\n    printer.print(\"Validation successful, fitting the model...\")\n\n    # Fix seed\n    fixSeed(self.randomstate)\n    d = Dispatcher(sequential=self.sequential,threshold=self.threshold,repeats=n_repeats,folds=n_splits)\n    d.dispatch(nqubits=self.nqubits,randomstate=self.randomstate,predictions=self.predictions,numPredictors=self.numPredictors,numLayers=self.numLayers,classifiers=self.classifiers,ansatzs=self.ansatzs,backend=self.backend,embeddings=self.embeddings,features=self.features,learningRate=self.learningRate,epochs=self.epochs,runs=self.runs,maxSamples=self.maxSamples,verbose=self.verbose,customMetric=self.customMetric,customImputerNum=self.customImputerNum,customImputerCat=self.customImputerCat,X=X ,y=y,shots=self.shots,showTable=showTable,batch=self.batchSize,mode=\"cross-validation\")\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/DiegoGV-Uniovi/lazyqml/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>lazyqml could always use more documentation, whether as part of the official lazyqml docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/DiegoGV-Uniovi/lazyqml/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up lazyqml for local development.</p> <ol> <li> <p>Fork the lazyqml repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/lazyqml.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv lazyqml\n$ cd lazyqml/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 lazyqml tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/DiegoGV-Uniovi/lazyqml/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"faq/","title":"FAQ","text":""},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install lazyqml, run this command in your terminal:</p> <pre><code>pip install lazyqml\n</code></pre> <p>This is the preferred method to install lazyqml, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>To install lazyqml from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/DiegoGV-Uniovi/lazyqml\n</code></pre>"},{"location":"lazyqml/","title":"QuantumClassifier","text":""},{"location":"lazyqml/#quantumclassifier-parameters","title":"QuantumClassifier Parameters:","text":""},{"location":"lazyqml/#core-parameters","title":"Core Parameters:","text":"<ul> <li><code>nqubits</code>: <code>Set[int]</code></li> <li>Description: Set of qubit indices, where each value must be greater than 0.</li> <li> <p>Validation: Ensures that all elements are integers &gt; 0.</p> </li> <li> <p><code>randomstate</code>: <code>int</code></p> </li> <li>Description: Seed value for random number generation.</li> <li> <p>Default: <code>1234</code></p> </li> <li> <p><code>predictions</code>: <code>bool</code></p> </li> <li>Description: Flag to determine if predictions are enabled.</li> <li>Default: <code>False</code></li> </ul>"},{"location":"lazyqml/#model-structure-parameters","title":"Model Structure Parameters:","text":"<ul> <li><code>numPredictors</code>: <code>int</code></li> <li>Description: Number of predictors used in the QNN with bagging.</li> <li>Constraints: Must be greater than 0.</li> <li> <p>Default: <code>10</code></p> </li> <li> <p><code>numLayers</code>: <code>int</code></p> </li> <li>Description: Number of layers in the Quantum Neural Networks.</li> <li>Constraints: Must be greater than 0.</li> <li>Default: <code>5</code></li> </ul>"},{"location":"lazyqml/#set-based-configuration-parameters","title":"Set-Based Configuration Parameters:","text":"<ul> <li><code>classifiers</code>: <code>Set[Model]</code></li> <li>Description: Set of classifier models.</li> <li>Constraints: Must contain at least one classifier.</li> <li>Default: <code>{Model.ALL}</code></li> <li> <p>Options: <code>{Model.QNN, Model.QSVM, Model.QNN_BAG}</code></p> </li> <li> <p><code>ansatzs</code>: <code>Set[Ansatzs]</code></p> </li> <li>Description: Set of quantum ansatz configurations.</li> <li>Constraints: Must contain at least one ansatz.</li> <li>Default: <code>{Ansatzs.ALL}</code></li> <li> <p>Options: <code>{Ansatzs.RX, Ansatzs.RZ, Ansatzs.RY, Ansatzs.ZZ, Ansatzs.AMP}</code></p> </li> <li> <p><code>embeddings</code>: <code>Set[Embedding]</code></p> </li> <li>Description: Set of embedding strategies.</li> <li>Constraints: Must contain at least one embedding.</li> <li>Default: <code>{Embedding.ALL}</code></li> <li> <p>Options: <code>{Embedding.HCZRX, Embedding.TREE_TENSOR, Embedding.TWO_LOCAL, Embedding.HARDWARE_EFFICENT}</code></p> </li> <li> <p><code>features</code>: <code>Set[float]</code></p> </li> <li>Description: Set of feature values (must be between 0 and 1).</li> <li>Constraints: Values &gt; 0 and &lt;= 1.</li> <li>Default: <code>{0.3, 0.5, 0.8}</code></li> </ul>"},{"location":"lazyqml/#training-parameters","title":"Training Parameters:","text":"<ul> <li><code>learningRate</code>: <code>float</code></li> <li>Description: Learning rate for optimization.</li> <li>Constraints: Must be greater than 0.</li> <li> <p>Default: <code>0.01</code></p> </li> <li> <p><code>epochs</code>: <code>int</code></p> </li> <li>Description: Number of training epochs.</li> <li>Constraints: Must be greater than 0.</li> <li> <p>Default: <code>100</code></p> </li> <li> <p><code>batchSize</code>: <code>int</code></p> </li> <li>Description: Size of each batch during training.</li> <li>Constraints: Must be greater than 0.</li> <li>Default: <code>8</code></li> </ul>"},{"location":"lazyqml/#threshold-and-sampling","title":"Threshold and Sampling:","text":"<ul> <li><code>threshold</code>: <code>int</code></li> <li>Description: Decision threshold for parallelization, if the model is bigger than this threshold it will use GPU.</li> <li>Constraints: Must be greater than 0.</li> <li> <p>Default: <code>22</code></p> </li> <li> <p><code>maxSamples</code>: <code>float</code></p> </li> <li>Description: Maximum proportion of samples to be used from the dataset characteristics.</li> <li>Constraints: Between 0 and 1.</li> <li>Default: <code>1.0</code></li> </ul>"},{"location":"lazyqml/#logging-and-metrics","title":"Logging and Metrics:","text":"<ul> <li><code>verbose</code>: <code>bool</code></li> <li>Description: Flag for detailed output during training.</li> <li> <p>Default: <code>False</code></p> </li> <li> <p><code>customMetric</code>: <code>Optional[Callable]</code></p> </li> <li>Description: User-defined metric function for evaluation.</li> <li>Validation:<ul> <li>Function must accept <code>y_true</code> and <code>y_pred</code> as the first two arguments.</li> <li>Must return a scalar value (int or float).</li> <li>Function execution is validated with dummy arguments.</li> </ul> </li> <li>Default: <code>None</code></li> </ul>"},{"location":"lazyqml/#custom-preprocessors","title":"Custom Preprocessors:","text":"<ul> <li><code>customImputerNum</code>: <code>Optional[Any]</code></li> <li>Description: Custom numeric data imputer.</li> <li>Validation:<ul> <li>Must be an object with <code>fit</code>, <code>transform</code>, and optionally <code>fit_transform</code> methods.</li> <li>Validated with dummy data.</li> </ul> </li> <li> <p>Default: <code>None</code></p> </li> <li> <p><code>customImputerCat</code>: <code>Optional[Any]</code></p> </li> <li>Description: Custom categorical data imputer.</li> <li>Validation:<ul> <li>Must be an object with <code>fit</code>, <code>transform</code>, and optionally <code>fit_transform</code> methods.</li> <li>Validated with dummy data.</li> </ul> </li> <li>Default: <code>None</code></li> </ul>"},{"location":"lazyqml/#functions","title":"Functions:","text":""},{"location":"lazyqml/#fit","title":"<code>fit</code>","text":"<p><pre><code>fit(self, X, y, test_size=0.4, showTable=True)\n</code></pre> Fits classification algorithms to <code>X</code> and <code>y</code> using a hold-out approach. Predicts and scores on a test set determined by <code>test_size</code>.</p>"},{"location":"lazyqml/#parameters","title":"Parameters:","text":"<ul> <li><code>X</code>: Input features (DataFrame or compatible format).</li> <li><code>y</code>: Target labels (must be numeric, e.g., via <code>LabelEncoder</code> or <code>OrdinalEncoder</code>).</li> <li><code>test_size</code>: Proportion of the dataset to use as the test set. Default is <code>0.4</code>.</li> <li><code>showTable</code>: Display a table with results. Default is <code>True</code>.</li> </ul>"},{"location":"lazyqml/#behavior","title":"Behavior:","text":"<ul> <li>Validates the compatibility of input dimensions.</li> <li>Automatically applies PCA transformation for incompatible dimensions.</li> <li>Requires all categories to be present in training data.</li> </ul>"},{"location":"lazyqml/#repeated_cross_validation","title":"<code>repeated_cross_validation</code>","text":"<p><pre><code>repeated_cross_validation(self, X, y, n_splits=10, n_repeats=5, showTable=True)\n</code></pre> Performs repeated cross-validation on the dataset using the specified splits and repeats.</p>"},{"location":"lazyqml/#parameters_1","title":"Parameters:","text":"<ul> <li><code>X</code>: Input features (DataFrame or compatible format).</li> <li><code>y</code>: Target labels (must be numeric).</li> <li><code>n_splits</code>: Number of folds for splitting the dataset. Default is <code>10</code>.</li> <li><code>n_repeats</code>: Number of times cross-validation is repeated. Default is <code>5</code>.</li> <li><code>showTable</code>: Display a table with results. Default is <code>True</code>.</li> </ul>"},{"location":"lazyqml/#behavior_1","title":"Behavior:","text":"<ul> <li>Uses <code>RepeatedStratifiedKFold</code> for generating splits.</li> <li>Aggregates results from multiple train-test splits.</li> </ul>"},{"location":"lazyqml/#leave_one_out","title":"<code>leave_one_out</code>","text":"<p><pre><code>leave_one_out(self, X, y, showTable=True)\n</code></pre> Performs leave-one-out cross-validation on the dataset.</p>"},{"location":"lazyqml/#parameters_2","title":"Parameters:","text":"<ul> <li><code>X</code>: Input features (DataFrame or compatible format).</li> <li><code>y</code>: Target labels (must be numeric).</li> <li><code>showTable</code>: Display a table with results. Default is <code>True</code>.</li> </ul>"},{"location":"lazyqml/#behavior_2","title":"Behavior:","text":"<ul> <li>Uses <code>LeaveOneOut</code> for generating train-test splits.</li> <li>Evaluates the model on each split and aggregates results.</li> </ul>"},{"location":"usage/","title":"Usage","text":"<p>To use LazyQML:</p> <pre><code>from sklearn.datasets import load_iris\nfrom lazyqml.lazyqml import *\n\n# Load data\ndata = load_iris()\nX = data.data\ny = data.target\n\nclassifier = QuantumClassifier(nqubits={4}, classifiers={Model.QNN, Model.QSVM}, epochs=10)\n\n# Fit and predict\nclassifier.fit(X=X, y=y, test_size=0.4)\n</code></pre>"}]}